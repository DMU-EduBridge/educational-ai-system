#!/usr/bin/env python3
"""
Educational AI System - RAG Pipeline
ë©”ì¸ CLI ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import click
import json
import sys
import os
from pathlib import Path
from typing import Optional, List, Dict, Any
import traceback

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from src.utils.config import get_settings, Settings
    from src.utils.logger import setup_application_logger, get_logger
    from src.rag.document_processor import DocumentProcessor
    from src.rag.embeddings import EmbeddingsManager
    from src.rag.vector_store import VectorStore
    from src.rag.retriever import RAGRetriever
    from src.models.llm_client import LLMClient
    from src.models.question_generator import QuestionGenerator
    from src.evaluation.quality_assessor import QualityAssessor
except ImportError:
    # íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ëœ ê²½ìš°ì˜ import
    from utils.config import get_settings, Settings
    from utils.logger import setup_application_logger, get_logger
    from rag.document_processor import DocumentProcessor
    from rag.embeddings import EmbeddingsManager
    from rag.vector_store import VectorStore
    from rag.retriever import RAGRetriever
    from models.llm_client import LLMClient
    from models.question_generator import QuestionGenerator
    from evaluation.quality_assessor import QualityAssessor


class RAGPipeline:
    """RAG íŒŒì´í”„ë¼ì¸ ë©”ì¸ í´ë˜ìŠ¤"""

    def __init__(self, settings: Optional[Settings] = None):
        self.settings = settings or get_settings()
        self.logger = get_logger(__name__)

        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self._initialize_components()

    def _initialize_components(self):
        """RAG íŒŒì´í”„ë¼ì¸ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
        try:
            # API í‚¤ ê²€ì¦
            if not self.settings.validate_api_key():
                raise ValueError("Invalid or missing OpenAI API key")

            # ê° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
            self.document_processor = DocumentProcessor()

            self.embeddings_manager = EmbeddingsManager(
                model_name=self.settings.openai_embedding_model,
                api_key=self.settings.openai_api_key
            )

            self.vector_store = VectorStore(
                collection_name=self.settings.chroma_collection_name,
                persist_directory=self.settings.chroma_db_path
            )

            self.retriever = RAGRetriever(
                vector_store=self.vector_store,
                embeddings_manager=self.embeddings_manager
            )

            self.llm_client = LLMClient(
                model_name=self.settings.openai_model,
                api_key=self.settings.openai_api_key,
                temperature=self.settings.openai_temperature,
                max_tokens=self.settings.openai_max_tokens
            )

            self.question_generator = QuestionGenerator(
                llm_client=self.llm_client,
                retriever=self.retriever
            )

            self.quality_assessor = QualityAssessor(llm_client=self.llm_client)

            self.logger.info("RAG Pipeline initialized successfully")

        except Exception as e:
            self.logger.error(f"Failed to initialize RAG Pipeline: {str(e)}")
            raise

    def process_textbook(self, file_path: str, subject: str, unit: str) -> Dict[str, Any]:
        """êµê³¼ì„œ ì²˜ë¦¬ ë° ë²¡í„° DB ì €ì¥"""
        try:
            self.logger.info(f"Processing textbook: {file_path}")

            # 1. ë¬¸ì„œ ë¡œë“œ ë° ì²˜ë¦¬
            documents = self.document_processor.load_textbook(file_path, subject, unit)
            self.logger.info(f"Loaded {len(documents)} document chunks")

            # 2. ì„ë² ë”© ìƒì„±
            texts = [doc.content for doc in documents]
            cost_info = self.embeddings_manager.estimate_cost(texts)
            self.logger.info(f"Estimated embedding cost: ${cost_info['estimated_cost_usd']:.4f}")

            embeddings = self.embeddings_manager.generate_embeddings(texts)
            self.logger.info(f"Generated {len(embeddings)} embeddings")

            # 3. ë²¡í„° ì €ì¥ì†Œì— ì €ì¥
            success = self.vector_store.add_documents(documents, embeddings)

            if success:
                result = {
                    'status': 'success',
                    'processed_chunks': len(documents),
                    'total_tokens': cost_info['total_tokens'],
                    'estimated_cost': cost_info['estimated_cost_usd'],
                    'subject': subject,
                    'unit': unit,
                    'source_file': Path(file_path).name
                }
                self.logger.info("Textbook processing completed successfully")
                return result
            else:
                raise Exception("Failed to store documents in vector database")

        except Exception as e:
            self.logger.error(f"Error processing textbook: {str(e)}")
            raise

    def generate_questions(self,
                         subject: str,
                         unit: str,
                         difficulty: str = 'medium',
                         count: int = 1) -> List[Dict[str, Any]]:
        """ë¬¸ì œ ìƒì„±"""
        try:
            self.logger.info(f"Generating {count} questions for {subject} - {unit} ({difficulty})")

            if count == 1:
                question = self.question_generator.generate_question(subject, unit, difficulty)
                return [question]
            else:
                questions = self.question_generator.generate_batch_questions(
                    subject, unit, count, difficulty
                )
                return questions

        except Exception as e:
            self.logger.error(f"Error generating questions: {str(e)}")
            raise

    def evaluate_questions(self, question_file: str, subject: str, unit: str) -> List[Dict[str, Any]]:
        """ìƒì„±ëœ ë¬¸ì œ í’ˆì§ˆ í‰ê°€"""
        try:
            self.logger.info(f"Evaluating questions from {question_file}")
            with open(question_file, 'r', encoding='utf-8') as f:
                questions_data = json.load(f)

            results = []
            for i, question_data in enumerate(questions_data):
                self.logger.debug(f"Evaluating question {i+1}")
                # Retrieve context based on the question text itself to find the most relevant source
                retrieved_docs = self.retriever.retrieve_documents(
                    query=question_data['question'],
                    subject=subject,
                    unit=unit
                )
                source_context = "\n\n".join([doc.content for doc in retrieved_docs])

                if not source_context:
                    self.logger.warning(f"Could not retrieve source context for question {i+1}. Skipping assessment.")
                    continue

                assessment = self.quality_assessor.assess_question(question_data, source_context)
                results.append({"question_id": i + 1, "assessment": assessment, "original_question": question_data})
            
            self.logger.info(f"Finished evaluating {len(results)} questions.")
            return results
        except Exception as e:
            self.logger.error(f"Error evaluating questions: {str(e)}")
            raise

    def get_status(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        try:
            # ë²¡í„° DB ì •ë³´
            collection_info = self.vector_store.get_collection_info()

            # LLM ì‚¬ìš©ëŸ‰
            llm_usage = self.llm_client.track_usage()

            # ë¬¸ì œ ìƒì„± í†µê³„
            question_stats = self.question_generator.get_question_statistics()

            status = {
                'vector_store': collection_info,
                'llm_usage': llm_usage,
                'question_generation': question_stats,
                'settings': self.settings.to_dict()
            }

            return status

        except Exception as e:
            self.logger.error(f"Error getting status: {str(e)}")
            raise

    def test_pipeline(self) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
        try:
            self.logger.info("Starting pipeline test")

            # í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸
            test_content = "ì¼ì°¨í•¨ìˆ˜ëŠ” y = ax + b í˜•íƒœì˜ í•¨ìˆ˜ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œ aëŠ” ê¸°ìš¸ê¸°, bëŠ” yì ˆí¸ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤."

            # ì„ì‹œ í…ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            test_file = Path("./test_content.txt")
            test_file.write_text(test_content, encoding='utf-8')

            try:
                # 1. ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
                process_result = self.process_textbook(str(test_file), "ìˆ˜í•™", "ì¼ì°¨í•¨ìˆ˜")

                # 2. ë¬¸ì œ ìƒì„± í…ŒìŠ¤íŠ¸
                questions = self.generate_questions("ìˆ˜í•™", "ì¼ì°¨í•¨ìˆ˜", "medium", 1)

                # 3. ìƒíƒœ í™•ì¸
                status = self.get_status()

                test_result = {
                    'status': 'success',
                    'document_processing': process_result,
                    'question_generation': {
                        'generated_questions': len(questions),
                        'sample_question': questions[0] if questions else None
                    },
                    'system_status': status
                }

                self.logger.info("Pipeline test completed successfully")
                return test_result

            finally:
                # í…ŒìŠ¤íŠ¸ íŒŒì¼ ì •ë¦¬
                if test_file.exists():
                    test_file.unlink()

        except Exception as e:
            self.logger.error(f"Pipeline test failed: {str(e)}")
            raise


# CLI ì• í”Œë¦¬ì¼€ì´ì…˜ ì •ì˜
@click.group()
@click.option('--config', type=click.Path(exists=True), help='ì„¤ì • íŒŒì¼ ê²½ë¡œ')
@click.option('--debug', is_flag=True, help='ë””ë²„ê·¸ ëª¨ë“œ')
@click.option('--verbose', is_flag=True, help='ìƒì„¸ ì¶œë ¥')
@click.pass_context
def cli(ctx, config, debug, verbose):
    """Educational AI System - RAG Pipeline"""
    ctx.ensure_object(dict)

    # ì„¤ì • ë¡œë“œ
    if config:
        # ì„¤ì • íŒŒì¼ì´ ì œê³µëœ ê²½ìš° (í–¥í›„ êµ¬í˜„)
        settings = get_settings()
    else:
        settings = get_settings()

    # ë””ë²„ê·¸/ìƒì„¸ ëª¨ë“œ ì„¤ì •
    if debug:
        settings.debug = True
        settings.log_level = "DEBUG"
    if verbose:
        settings.verbose = True

    # ë¡œê±° ì„¤ì •
    logger = setup_application_logger(
        "educational_ai",
        config={
            'log_level': settings.log_level,
            'debug': settings.debug,
            'verbose': settings.verbose
        }
    )

    # ì»¨í…ìŠ¤íŠ¸ì— ì„¤ì •ê³¼ íŒŒì´í”„ë¼ì¸ ì €ì¥
    ctx.obj['settings'] = settings
    ctx.obj['logger'] = logger

    try:
        ctx.obj['pipeline'] = RAGPipeline(settings)
    except Exception as e:
        logger.error(f"Failed to initialize pipeline: {str(e)}")
        if debug:
            traceback.print_exc()
        sys.exit(1)


@cli.command()
@click.option('--file', required=True, type=click.Path(exists=True), help='êµê³¼ì„œ íŒŒì¼ ê²½ë¡œ')
@click.option('--subject', required=True, help='ê³¼ëª©ëª…')
@click.option('--unit', required=True, help='ë‹¨ì›ëª…')
@click.pass_context
def process_textbook(ctx, file, subject, unit):
    """êµê³¼ì„œ ì²˜ë¦¬ ë° ë²¡í„° DB ì €ì¥"""
    pipeline = ctx.obj['pipeline']
    logger = ctx.obj['logger']

    try:
        result = pipeline.process_textbook(file, subject, unit)

        click.echo(f"âœ… êµê³¼ì„œ ì²˜ë¦¬ ì™„ë£Œ!")
        click.echo(f"   íŒŒì¼: {result['source_file']}")
        click.echo(f"   ê³¼ëª©: {result['subject']}")
        click.echo(f"   ë‹¨ì›: {result['unit']}")
        click.echo(f"   ì²˜ë¦¬ëœ ì²­í¬: {result['processed_chunks']}ê°œ")
        click.echo(f"   í† í° ìˆ˜: {result['total_tokens']:,}")
        click.echo(f"   ì˜ˆìƒ ë¹„ìš©: ${result['estimated_cost']:.4f}")

    except Exception as e:
        click.echo(f"âŒ ì˜¤ë¥˜: {str(e)}", err=True)
        if ctx.obj['settings'].debug:
            traceback.print_exc()
        sys.exit(1)


@cli.command()
@click.option('--subject', required=True, help='ê³¼ëª©ëª…')
@click.option('--unit', required=True, help='ë‹¨ì›ëª…')
@click.option('--difficulty', default='medium', type=click.Choice(['easy', 'medium', 'hard']), help='ë‚œì´ë„')
@click.option('--count', default=1, type=int, help='ìƒì„±í•  ë¬¸ì œ ìˆ˜')
@click.option('--output', type=click.Path(), help='ê²°ê³¼ ì €ì¥ íŒŒì¼ (JSON)')
@click.pass_context
def generate_questions(ctx, subject, unit, difficulty, count, output):
    """ë¬¸ì œ ìƒì„±"""
    pipeline = ctx.obj['pipeline']
    logger = ctx.obj['logger']

    try:
        questions = pipeline.generate_questions(subject, unit, difficulty, count)

        click.echo(f"âœ… ë¬¸ì œ ìƒì„± ì™„ë£Œ! ({len(questions)}ê°œ)")
        click.echo()

        for i, question in enumerate(questions, 1):
            click.echo(f"=== ë¬¸ì œ {i} ===")
            click.echo(f"ë‚œì´ë„: {question['difficulty']}")
            click.echo(f"ê³¼ëª©: {question['subject']} - {question['unit']}")
            click.echo()
            click.echo(f"ë¬¸ì œ: {question['question']}")
            click.echo()
            click.echo("ì„ íƒì§€:")
            for j, option in enumerate(question['options'], 1):
                marker = "âœ“" if j == question['correct_answer'] else " "
                click.echo(f"  {marker} {j}. {option}")
            click.echo()
            click.echo(f"í•´ì„¤: {question['explanation']}")
            click.echo("-" * 50)

        # íŒŒì¼ ì €ì¥
        if output:
            output_path = Path(output)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(questions, f, ensure_ascii=False, indent=2)

            click.echo(f"ğŸ’¾ ê²°ê³¼ê°€ {output}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        click.echo(f"âŒ ì˜¤ë¥˜: {str(e)}", err=True)
        if ctx.obj['settings'].debug:
            traceback.print_exc()
        sys.exit(1)


@cli.command()
@click.option('--question-file', required=True, type=click.Path(exists=True), help='í‰ê°€í•  ë¬¸ì œ JSON íŒŒì¼')
@click.option('--subject', required=True, help='ê³¼ëª©ëª…')
@click.option('--unit', required=True, help='ë‹¨ì›ëª…')
@click.option('--output', type=click.Path(), help='í‰ê°€ ê²°ê³¼ ì €ì¥ íŒŒì¼ (JSON)')
@click.pass_context
def evaluate_questions(ctx, question_file, subject, unit, output):
    """ìƒì„±ëœ ë¬¸ì œì˜ í’ˆì§ˆì„ í‰ê°€í•©ë‹ˆë‹¤."""
    pipeline = ctx.obj['pipeline']
    logger = ctx.obj['logger']

    try:
        results = pipeline.evaluate_questions(question_file, subject, unit)
        click.echo(f"âœ… ë¬¸ì œ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ! ({len(results)}ê°œ)")
        click.echo("=" * 50)

        for result in results:
            assessment = result['assessment']
            if 'error' in assessment:
                click.echo(f"ID {result['question_id']} í‰ê°€ ì‹¤íŒ¨: {assessment['error']}", err=True)
                continue

            click.echo(f"### ë¬¸ì œ ID: {result['question_id']} ###")
            click.echo(f"  ì§ˆë¬¸: {result['original_question']['question'][:50]}...")
            click.echo(f"  ì‚¬ìš© ê°€ëŠ¥ì„±: {'ğŸ‘ Yes' if assessment.get('is_usable') else 'ğŸ‘ No'}")
            click.echo(f"  ì¢…í•© ì ìˆ˜: {assessment.get('overall_score', 'N/A')}")
            click.echo("  ì„¸ë¶€ ì ìˆ˜:")
            for criterion, values in assessment.get('scores', {}).items():
                click.echo(f"    - {criterion.capitalize()}: {values.get('score')}/5")
            click.echo(f"  ìš”ì•½: {assessment.get('summary', 'N/A')}")
            click.echo("-" * 50)

        if output:
            output_path = Path(output)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            click.echo(f"ğŸ’¾ í‰ê°€ ê²°ê³¼ê°€ {output}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        click.echo(f"âŒ ì˜¤ë¥˜: {str(e)}", err=True)
        if ctx.obj['settings'].debug:
            traceback.print_exc()
        sys.exit(1)


@cli.command()
@click.pass_context
def status(ctx):
    """ë²¡í„° DB ìƒíƒœ í™•ì¸"""
    pipeline = ctx.obj['pipeline']
    logger = ctx.obj['logger']

    try:
        status_info = pipeline.get_status()

        click.echo("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        click.echo("=" * 50)

        # ë²¡í„° ì €ì¥ì†Œ ì •ë³´
        vs_info = status_info['vector_store']
        click.echo(f"ğŸ—„ï¸  ë²¡í„° ì €ì¥ì†Œ:")
        click.echo(f"   ì»¬ë ‰ì…˜: {vs_info['collection_name']}")
        click.echo(f"   ì´ ë¬¸ì„œ: {vs_info['total_documents']:,}ê°œ")
        click.echo(f"   ê³¼ëª©: {', '.join(vs_info['subjects']) if vs_info['subjects'] else 'ì—†ìŒ'}")
        click.echo(f"   ë‹¨ì›: {', '.join(vs_info['units']) if vs_info['units'] else 'ì—†ìŒ'}")
        click.echo()

        # LLM ì‚¬ìš©ëŸ‰
        llm_info = status_info['llm_usage']
        click.echo(f"ğŸ¤– LLM ì‚¬ìš©ëŸ‰:")
        click.echo(f"   ëª¨ë¸: {llm_info['model']}")
        click.echo(f"   ì´ ìš”ì²­: {llm_info['total_requests']:,}íšŒ")
        click.echo(f"   ì´ í† í°: {llm_info['total_tokens']:,}ê°œ")
        click.echo(f"   ì´ ë¹„ìš©: ${llm_info['total_cost_usd']:.4f}")
        click.echo()

        # ë¬¸ì œ ìƒì„± í†µê³„
        qg_info = status_info['question_generation']
        click.echo(f"ğŸ“ ë¬¸ì œ ìƒì„± í†µê³„:")
        click.echo(f"   ìƒì„±ëœ ë¬¸ì œ: {qg_info['total_questions']}ê°œ")
        if qg_info['by_difficulty']:
            click.echo(f"   ë‚œì´ë„ë³„: {qg_info['by_difficulty']}")

    except Exception as e:
        click.echo(f"âŒ ì˜¤ë¥˜: {str(e)}", err=True)
        if ctx.obj['settings'].debug:
            traceback.print_exc()
        sys.exit(1)


@cli.command()
@click.pass_context
def test_pipeline(ctx):
    """ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸"""
    pipeline = ctx.obj['pipeline']
    logger = ctx.obj['logger']

    try:
        click.echo("ğŸ§ª íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        result = pipeline.test_pipeline()

        click.echo("âœ… íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        click.echo()
        click.echo("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
        click.echo(f"   ë¬¸ì„œ ì²˜ë¦¬: {result['document_processing']['processed_chunks']}ê°œ ì²­í¬")
        click.echo(f"   ë¬¸ì œ ìƒì„±: {result['question_generation']['generated_questions']}ê°œ")
        click.echo()

        if result['question_generation']['sample_question']:
            sample = result['question_generation']['sample_question']
            click.echo("ğŸ“ ìƒì„±ëœ ìƒ˜í”Œ ë¬¸ì œ:")
            click.echo(f"   {sample['question']}")

        click.echo()
        click.echo("âœ¨ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ê°€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤!")

    except Exception as e:
        click.echo(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}", err=True)
        if ctx.obj['settings'].debug:
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    cli()